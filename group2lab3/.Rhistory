require(rpart)
Swiss_rpart <- rpart(Fertility ~ Agriculture + Education + Catholic, data = swiss)
help(rpart)
help(Fertility)
Fertility
Fertility
Agriculture
View(Swiss_rpart)
swiss
plot(swiss_rpart) # try some different plot options
plot(swiss_rpart) # try some different plot options
Swiss_rpart <- rpart(Fertility ~ Agriculture + Education + Catholic, data = swiss)
plot(swiss_rpart) # try some different plot options
swiss_rpart <- rpart(Fertility ~ Agriculture + Education + Catholic, data = swiss)
plot(swiss_rpart) # try some different plot options
text(swiss_rpart) # try some different text options
plot(swiss_rpart) # try some different plot options
text(swiss_rpart) # try some different text options
help(text)
require(party)
treeSwiss<-ctree(Species ~ ., data=iris)
plot(treeSwiss)
cforest(Species ~ ., data=iris, controls=cforest_control(mtry=2, mincriterion=0))
treeFert<-ctree(Fertility ~ Agriculture + Education + Catholic, data = swiss)
cforest(Fertility ~ Agriculture + Education + Catholic, data = swiss, controls=cforest_control(mtry=2, mincriterion=0))
treeSwiss<-ctree(Species ~ ., data=iris)
plot(treeSwiss)
plot(treeFert)
help(cforest)
treeSwiss<-ctree(Species ~ ., data=iris)
plot(treeSwiss)
plot(cforest)
tree = cforest(Species ~ ., data=iris, controls=cforest_control(mtry=2, mincriterion=0))
plot(tree)
tree = cforest(Species ~ ., data=iris, controls=cforest_control(mtry=2, mincriterion=0))
plot(tree)
treeFert<-ctree(Fertility ~ Agriculture + Education + Catholic, data = swiss)
cforest(Fertility ~ Agriculture + Education + Catholic, data = swiss, controls=cforest_control(mtry=2, mincriterion=0))
library(tree)
tr <- tree(Species ~ ., data=iris)
tr
tr$frame
plot(tr)
text(tr)
plot(swiss_rpart) # try some different plot options
text(swiss_rpart) # try some different text options
prp(tr)
library(rpart.plot)
prp(tr)
install.packages("rpart.plot")
library(rpart.plot)
prp(tr)
prp(treeSwiss)
prp(swiss_rpart)
cforest(Species ~ ., data=iris, controls=cforest_control(mtry=2, mincriterion=0))
treeFert<-ctree(Fertility ~ Agriculture + Education + Catholic, data = swiss)
prp(treeSwiss)
help(ctree)
# Conditional Inference Tree for Mileage
fit2M <- ctree(Mileage~Price + Country + Reliability + Type, data=na.omit(cu.summary))
summary(fit2M)
# plot tree
plot(fit2M, uniform=TRUE, main="CI Tree Tree for Mileage ")
text(fit2M, use.n=TRUE, all=TRUE, cex=.8)
# plot tree
plot(fit2M, uniform=TRUE, main="CI Tree Tree for Mileage ")
text(fit2M, use.n=TRUE, all=TRUE, cex=.8)
help(text)
text(fit2M, cex=.8)
text(fit2M)
# plot tree
plot(fit2M, uniform=TRUE, main="CI Tree Tree for Mileage ")
fitK <- ctree(Kyphosis ~ Age + Number + Start, data=kyphosis)
plot(fitK, main="Conditional Inference Tree for Kyphosis”)
fitK <- ctree(Kyphosis ~ Age + Number + Start, data=kyphosis)
fitK <- ctree(Kyphosis ~ Age + Number + Start, data=kyphosis)
plot(fitK, main="Conditional Inference Tree for Kyphosis")
kyphosis
fitK <- ctree(Kyphosis ~ Age + Number + Start, data=kyphosis)
plot(fitK, main="Conditional Inference Tree for Kyphosis")
plot(fitK, main="Conditional Inference Tree for Kyphosis",type="simple")
plot(fitK, main="Conditional Inference Tree for Kyphosis")
plot(fitK, main="Conditional Inference Tree for Kyphosis",type="simple")
source("C:/Users/alden/Desktop/Data Analytics/group2_lab3/lab3_kknn1.R", echo=TRUE)
require(kknn)
data(iris)
m <- dim(iris)[1]
val <- sample(1:m, size = round(m/3), replace = FALSE, prob = rep(1/m, m))
iris.learn <- iris[-val,] 	# train
iris.valid <- iris[val,]	# test
iris.kknn <- train.kknn(Species~., iris.learn, distance = 1, kernel = c("triangular", "epanechnikov", "biweight", "triweight", "cos", "inv", "gaussian", "rank", "optimal") )
summary(iris.kknn)
table(predict(iris.kknn,iris.valid),iris.valid$Species)
head(iris.kknn$W)
head(iris.kknn$D)
head(iris.kknn$C)
head(iris.kknn$fitted.values)
help(iris.kknn)
??iris.kknn
help(train.kknn)
#?? W, D, C are not values in iris.knn
#head(iris.kknn$W)
#head(iris.kknn$D)
#head(iris.kknn$C)
head(iris.kknn$fitted.values)
Swiss_rpart <- rpart(Fertility ~ Agriculture + Education + Catholic, data = swiss)
plot(swiss_rpart) # try some different plot options
text(swiss_rpart) # try some different text options
require(randomForest)
fitKF <- randomForest(Kyphosis ~ Age + Number + Start,   data=kyphosis)
print(fitKF) 	# view results
importance(fitKF) # importance of each predictor
#
fitSwiss <- randomForest(Fertility ~ Agriculture + Education + Catholic, data = swiss)
print(fitSwiss) # view results
importance(fitSwiss) # importance of each predictor
varImpPlot(fitSwiss)
plot(fitSwiss)
getTree(fitSwiss,1, labelVar=TRUE)
help(randomForest) # look at all the package contents and the randomForest method options
# look at rfcv - random forest cross-validation -
help(rfcv)
# other data....
data(imports85)
View(imports85)
View(imports85)
# perform randomForest and other tree methods.....
fit_newdata = randomForest(price ~., data = imports85)
View(imports85)
View(imports85)
# perform randomForest and other tree methods.....
removed_missing_data = imports85 %>% select(!"normalizedLosses")
# perform randomForest and other tree methods.....
library(dplyr)
removed_missing_data = imports85 %>% select(!"normalizedLosses")
fit_newdata = randomForest(price ~., data = removed_missing_data)
na.omit(removed_missing_data)
removed_missing_data = imports85 %>% select(!"normalizedLosses") %>% na.omit()
removed_missing_data = imports85 %>% select(!"normalizedLosses") %>%
fit_newdata = randomForest(price ~., data = removed_missing_data)
removed_missing_data = imports85 %>% select(!"normalizedLosses") %>% na.omit()
fit_newdata = randomForest(price ~., data = removed_missing_data)
print(fit_newdata)
plot(fit_newdata)
abline(fit_newdata)
rfce(price ~., data = removed_missing_data)
# look at rfcv - random forest cross-validation -
help(rfcv)
rfcv(price ~., data = removed_missing_data)
rfcv(trainx = removed_missing_data[!"price"], trainy = removed_missing_data$price)
rfcv(trainx = removed_missing_data %>% select(!"price"), trainy = removed_missing_data$price)
cv = rfcv(trainx = removed_missing_data %>% select(!"price"), trainy = removed_missing_data$price)
plot(cv)
plot(price, cv)
plot(removed_missing_data$price, cv)
View(cv)
plot(removed_missing_data$price, cv$predicted)
plot(removed_missing_data$price, cv$predicted[1])
cv$predicted
cv$predicted[1]
removed_missing_data$price
with(cv, plot(n.var, error.cv, log = "x"))
# Regression Tree Example
require(rpart)
# build the  tree
fitM <- rpart(Mileage~Price + Country + Reliability + Type, method="anova", data=cu.summary)
printcp(fitM) # display the results
plotcp(fitM)
help(plotcp)
help(rpart)
help(printcp)
plotcp(fitM)
summary(fitM)
par(mfrow=c(1,2))
rsq.rpart(fitM) # visualize cross-validation results
help(rsq)
help(rsq.rpart)
# plot tree
plot(fitM, uniform=TRUE, main="Regression Tree for Mileage ")
text(fitM, use.n=TRUE, all=TRUE, cex=.8)
# prune the tree
pfitM<- prune(fitM, cp=0.01160389) # from cptable??? adjust this to see the effect
printcp(fitM) # display the results
plotcp(fitM)
# prune the tree
pfitM<- prune(fitM, cp=0.01160389) # from cptable??? adjust this to see the effect
# plot the pruned tree
plot(pfitM, uniform=TRUE, main="Pruned Regression Tree for Mileage")
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
post(pfitM, file = ”ptree2.ps", title = "Pruned Regression Tree for Mileage”)
# cv result
rsq.rpart(pfitM)
# prune the tree
pfitM<- prune(fitM, cp=0.01160389) # from cptable??? adjust this to see the effect
# cv result
rsq.rpart(pfitM)
# cv result
rsq.rpart(pfitM)
rsq.rpart(fitM) # visualize cross-validation results
# cv result
rsq.rpart(pfitM)
# plot the pruned tree
plot(pfitM, uniform=TRUE, main="Pruned Regression Tree for Mileage")
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
post(pfitM, file = ”ptree2.ps", title = "Pruned Regression Tree for Mileage”)
# cv result
par()
rsq.rpart(pfitM)
# plot the pruned tree
par(mfrow = c(1,2))
plot(pfitM, uniform=TRUE, main="Pruned Regression Tree for Mileage")
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
post(pfitM, file = ”ptree2.ps", title = "Pruned Regression Tree for Mileage”)
# plot the pruned tree
plot(pfitM, uniform=TRUE, main="Pruned Regression Tree for Mileage")
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
# cv result
par()
rsq.rpart(pfitM)
# plot the pruned tree
plot(pfitM, uniform=TRUE, main="Pruned Regression Tree for Mileage")
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
post(pfitM, file = ”ptree2.ps", title = "Pruned Regression Tree for Mileage”)
# cv result
par()
rsq.rpart(pfitM)
# prune the tree
pfitM<- prune(fitM, cp=0.11160389) # from cptable??? adjust this to see the effect
# cv result
par()
rsq.rpart(pfitM)
# plot the pruned tree
plot(pfitM, uniform=TRUE, main="Pruned Regression Tree for Mileage")
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
post(pfitM, file = ”ptree2.ps", title = "Pruned Regression Tree for Mileage”)
# cv result
par()
rsq.rpart(pfitM)
post(pfitM, file = ”ptree2.ps"", title = "Pruned Regression Tree for Mileage”)
post(pfitM, file = "ptree2.ps", title = "Pruned Regression Tree for Mileage”)
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
text(pfitM, use.n=TRUE, all=TRUE, cex=.8)
post(pfitM, file = "ptree2.ps", title = "Pruned Regression Tree for Mileage”)
post(pfitM, file = "ptree2.ps", title = "Pruned Regression Tree for Mileage")
post(pfitM, file = "ptree2.ps", title = "Pruned Regression Tree for Mileage")
library(e1071)
library(rpart)
data(Glass, package="mlbench")
library("mlbench")
library(mlbench)
data(Glass, package="mlbench")
install.packages("mlbench")
library(mlbench)
data(Glass, package="mlbench")
index <- 1:nrow(Glass)
testindex <- sample(index, trunc(length(index)/3))
testset <- Glass[testindex,]
trainset <- Glass[-testindex,]
rpart.model <- rpart(Type ~ ., data = trainset)
rpart.pred <- predict(rpart.model, testset[,-10], type = "class")
printcp(rpart.model)
plotcp(rpart.model)
rsq.rpart(rpart.model)
par()
rsq.rpart(rpart.model)
par.reset()
rsq.rpart(rpart.model)
rsq.rpart(rpart.model)
par(mfrow=c(2,1))
rsq.rpart(rpart.model)
par(mfrow=c(1,2))
rsq.rpart(rpart.model)
print(rpart.model)
plot(rpart.model,compress=TRUE)
text(rpart.model, use.n=TRUE)
plot(rpart.pred)
rpart.pred
fitK <- rpart(Kyphosis ~ Age + Number + Start, method="class", data=kyphosis)
printcp(fitK) # display the results
plotcp(fitK) # visualize cross-validation results
summary(fitK) # detailed summary of splits
# plot tree
plot(fitK, uniform=TRUE, main="Classification Tree for Kyphosis")
text(fitK, use.n=TRUE, all=TRUE, cex=.8)
# plot tree
par(mfrow = c(1,1))
plot(fitK, uniform=TRUE, main="Classification Tree for Kyphosis")
text(fitK, use.n=TRUE, all=TRUE, cex=.8)
# create attractive postscript plot of tree
# create attractive postscript plot of tree
post(fitK, file = "kyphosistree.ps", title = "Classification Tree for Kyphosis") # might need to convert to PDF (distill)
pfitK<- prune(fitK, cp=   fitK$cptable[which.min(fitK$cptable[,"xerror"]),"CP"])
plot(pfitK, uniform=TRUE, main="Pruned Classification Tree for Kyphosis")
pfitK<- prune(fitK, cp=   fitK$cptable[which.min(fitK$cptable[,"xerror"]),"CP"])
print(pfitK)
plotcp(fitK) # visualize cross-validation results
summary(fitK) # detailed summary of splits
# lol this literally made only the root
pfitK = prune(fitK, cp = 0.059)
print(pfitK)
plot(pfitK, uniform=TRUE, main="Pruned Classification Tree for Kyphosis")
text(pfitK, use.n=TRUE, all=TRUE, cex=.8)
post(pfitK, file = “ptree.ps", title = "Pruned Classification Tree for Kyphosis”)
post(pfitK, file = "ptree.ps", title = "Pruned Classification Tree for Kyphosis”)
post(pfitK, file = "ptree.ps", title = "Pruned Classification Tree for Kyphosis")
post(pfitK, file = "ptree2.ps", title = "Pruned Classification Tree for Kyphosis")
plot(fitK, uniform=TRUE, main="Classification Tree for Kyphosis")
text(fitK, use.n=TRUE, all=TRUE, cex=.8)
plotcp(fitK) # visualize cross-validation results
summary(fitK) # detailed summary of splits
# lol this literally made only the root
pfitK = prune(fitK, cp = 0.059)
print(pfitK)
plot(pfitK, uniform=TRUE, main="Pruned Classification Tree for Kyphosis")
text(pfitK, use.n=TRUE, all=TRUE, cex=.8)
post(pfitK, file = "ptree2.ps", title = "Pruned Classification Tree for Kyphosis")
